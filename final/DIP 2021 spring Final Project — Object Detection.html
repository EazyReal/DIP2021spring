<!DOCTYPE html>

<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="mobile-web-app-capable" content="yes">
    <title>
        DIP 2021 spring Final Project — Object Detection - HackMD
    </title>
    <link rel="icon" type="image/png" href="https://hackmd.io/favicon.png">
    <link rel="apple-touch-icon" href="https://hackmd.io/apple-touch-icon.png">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ionicons/2.0.1/css/ionicons.min.css" integrity="sha256-3iu9jgsy9TpTwXKb7bNQzqWekRX7pPK+2OLj3R922fo=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/3.5.0/octicons.min.css" integrity="sha256-QiWfLIsCT02Sdwkogf6YMiQlj4NE84MKkzEMkZnMGdg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.1/themes/prism.min.css" integrity="sha256-vtR0hSWRc3Tb26iuN2oZHt3KRUomwTufNIf5/4oeCyg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/css/basic/emojify.min.css" integrity="sha256-UOrvMOsSDSrW6szVLe8ZDZezBxh5IoIfgTwdNDgTjiU=" crossorigin="anonymous" />
    <style>
        @import url(https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i|Source+Code+Pro:300,400,500|Source+Sans+Pro:300,300i,400,400i,600,600i|Source+Serif+Pro&subset=latin-ext);.hljs{display:block;background:#fff;padding:.5em;color:#333;overflow-x:auto}.hljs-comment,.hljs-meta{color:#969896}.hljs-emphasis,.hljs-quote,.hljs-string,.hljs-strong,.hljs-template-variable,.hljs-variable{color:#df5000}.hljs-keyword,.hljs-selector-tag,.hljs-type{color:#a71d5d}.hljs-attribute,.hljs-bullet,.hljs-literal,.hljs-number,.hljs-symbol{color:#0086b3}.hljs-built_in,.hljs-builtin-name{color:#005cc5}.hljs-name,.hljs-section{color:#63a35c}.hljs-tag{color:#333}.hljs-attr,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-selector-pseudo,.hljs-title{color:#795da3}.hljs-addition{color:#55a532;background-color:#eaffea}.hljs-deletion{color:#bd2c00;background-color:#ffecec}.hljs-link{text-decoration:underline}.markdown-body{font-size:16px;line-height:1.5;word-wrap:break-word}.markdown-body:after,.markdown-body:before{display:table;content:""}.markdown-body:after{clear:both}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:#c00}.markdown-body .anchor{float:left;padding-right:4px;margin-left:-20px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;padding:0;margin:24px 0;background-color:#e7e7e7;border:0}.markdown-body blockquote{font-size:16px;padding:0 1em;color:#777;border-left:.25em solid #ddd}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body kbd,.popover kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#555;vertical-align:middle;background-color:#fcfcfc;border:1px solid #ccc;border-bottom-color:#bbb;border-radius:3px;box-shadow:inset 0 -1px 0 #bbb}.markdown-body .loweralpha{list-style-type:lower-alpha}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:#000;vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 code,.markdown-body h1 tt,.markdown-body h2 code,.markdown-body h2 tt,.markdown-body h3 code,.markdown-body h3 tt,.markdown-body h4 code,.markdown-body h4 tt,.markdown-body h5 code,.markdown-body h5 tt,.markdown-body h6 code,.markdown-body h6 tt{font-size:inherit}.markdown-body h1{font-size:2em}.markdown-body h1,.markdown-body h2{padding-bottom:.3em;border-bottom:1px solid #eee}.markdown-body h2{font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{font-size:.85em;color:#777}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol.no-list,.markdown-body ul.no-list{padding:0;list-style-type:none}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{padding-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}.markdown-body dl dd{padding:0 16px;margin-bottom:16px}.markdown-body table{display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}.markdown-body table th{font-weight:700}.markdown-body table td,.markdown-body table th{padding:6px 13px;border:1px solid #ddd}.markdown-body table tr{background-color:#fff;border-top:1px solid #ccc}.markdown-body table tr:nth-child(2n){background-color:#f8f8f8}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:#fff}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:transparent}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{display:block;float:left;width:auto;padding:7px;margin:13px 0 0;overflow:hidden;border:1px solid #ddd}.markdown-body span.frame span img{display:block;float:left}.markdown-body span.frame span span{display:block;padding:5px 0 0;clear:both;color:#333}.markdown-body span.align-center{display:block;overflow:hidden;clear:both}.markdown-body span.align-center>span{display:block;margin:13px auto 0;overflow:hidden;text-align:center}.markdown-body span.align-center span img{margin:0 auto;text-align:center}.markdown-body span.align-right{display:block;overflow:hidden;clear:both}.markdown-body span.align-right>span{display:block;margin:13px 0 0;overflow:hidden;text-align:right}.markdown-body span.align-right span img{margin:0;text-align:right}.markdown-body span.float-left{display:block;float:left;margin-right:13px;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{display:block;float:right;margin-left:13px;overflow:hidden}.markdown-body span.float-right>span{display:block;margin:13px auto 0;overflow:hidden;text-align:right}.markdown-body code,.markdown-body tt{padding:0;padding-top:.2em;padding-bottom:.2em;margin:0;font-size:85%;background-color:rgba(0,0,0,.04);border-radius:3px}.markdown-body code:after,.markdown-body code:before,.markdown-body tt:after,.markdown-body tt:before{letter-spacing:-.2em;content:"\00a0"}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{text-decoration:inherit}.markdown-body pre{word-wrap:normal}.markdown-body pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:transparent;border:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{padding:16px;overflow:auto;font-size:85%;line-height:1.45;background-color:#f7f7f7;border-radius:3px}.markdown-body pre code,.markdown-body pre tt{display:inline;max-width:auto;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}.markdown-body pre code:after,.markdown-body pre code:before,.markdown-body pre tt:after,.markdown-body pre tt:before{content:normal}.markdown-body .csv-data td,.markdown-body .csv-data th{padding:5px;overflow:hidden;font-size:12px;line-height:1;text-align:left;white-space:nowrap}.markdown-body .csv-data .blob-line-num{padding:10px 8px 9px;text-align:right;background:#fff;border:0}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{font-weight:700;background:#f8f8f8;border-top:0}.news .alert .markdown-body blockquote{padding:0 0 0 40px;border:0 none}.activity-tab .news .alert .commits,.activity-tab .news .markdown-body blockquote{padding-left:0}.task-list-item{list-style-type:none}.task-list-item label{font-weight:400}.task-list-item.enabled label{cursor:pointer}.task-list-item+.task-list-item{margin-top:3px}.task-list-item-checkbox{float:left;margin:.31em 0 .2em -1.3em!important;vertical-align:middle;cursor:default!important}.markdown-body{padding-top:40px;padding-bottom:40px;max-width:758px;overflow:visible!important;position:relative}.markdown-body .emoji{vertical-align:top}.markdown-body pre{border:inherit!important}.markdown-body code{color:inherit!important}.markdown-body pre code .wrapper{display:-moz-inline-flex;display:-ms-inline-flex;display:-o-inline-flex;display:inline-flex}.markdown-body pre code .gutter{float:left;overflow:hidden;-webkit-user-select:none;user-select:none}.markdown-body pre code .gutter.linenumber{text-align:right;position:relative;display:inline-block;cursor:default;z-index:4;padding:0 8px 0 0;min-width:20px;box-sizing:content-box;color:#afafaf!important;border-right:3px solid #6ce26c!important}.markdown-body pre code .gutter.linenumber>span:before{content:attr(data-linenumber)}.markdown-body pre code .code{float:left;margin:0 0 0 16px}.markdown-body .gist .line-numbers{border-left:none;border-top:none;border-bottom:none}.markdown-body .gist .line-data{border:none}.markdown-body .gist table{border-spacing:0;border-collapse:inherit!important}.markdown-body code[data-gist-id]{background:none;padding:0}.markdown-body code[data-gist-id]:after,.markdown-body code[data-gist-id]:before{content:""}.markdown-body code[data-gist-id] .blob-num{border:unset}.markdown-body code[data-gist-id] table{overflow:unset;margin-bottom:unset}.markdown-body code[data-gist-id] table tr{background:unset}.markdown-body[dir=rtl] pre{direction:ltr}.markdown-body[dir=rtl] code{direction:ltr;unicode-bidi:embed}.markdown-body .alert>p{margin-bottom:0}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram,.markdown-body pre.vega{text-align:center;background-color:inherit;border-radius:0;white-space:inherit;overflow:visible}.markdown-body pre.abc>code,.markdown-body pre.flow-chart>code,.markdown-body pre.graphviz>code,.markdown-body pre.mermaid>code,.markdown-body pre.sequence-diagram>code,.markdown-body pre.vega>code{text-align:left}.markdown-body pre.abc>svg,.markdown-body pre.flow-chart>svg,.markdown-body pre.graphviz>svg,.markdown-body pre.mermaid>svg,.markdown-body pre.sequence-diagram>svg,.markdown-body pre.vega>svg{max-width:100%;height:100%}.markdown-body pre>code.wrap{white-space:pre-wrap;white-space:-moz-pre-wrap;white-space:-pre-wrap;white-space:-o-pre-wrap;word-wrap:break-word}.markdown-body .alert>p,.markdown-body .alert>ul{margin-bottom:0}.markdown-body summary{display:list-item}.markdown-body summary:focus{outline:none}.markdown-body details summary{cursor:pointer}.markdown-body details:not([open])>:not(summary){display:none}.markdown-body figure{margin:1em 40px}.markdown-body .mark,.markdown-body mark{background-color:#fff1a7}.vimeo,.youtube{cursor:pointer;display:table;text-align:center;background-position:50%;background-repeat:no-repeat;background-size:contain;background-color:#000;overflow:hidden}.vimeo,.youtube{position:relative;width:100%}.youtube{padding-bottom:56.25%}.vimeo img{width:100%;object-fit:contain;z-index:0}.youtube img{object-fit:cover;z-index:0}.vimeo iframe,.youtube iframe,.youtube img{width:100%;height:100%;position:absolute;top:0;left:0}.vimeo iframe,.youtube iframe{vertical-align:middle;z-index:1}.vimeo .icon,.youtube .icon{position:absolute;height:auto;width:auto;top:50%;left:50%;transform:translate(-50%,-50%);color:#fff;opacity:.3;transition:opacity .2s;z-index:0}.vimeo:hover .icon,.youtube:hover .icon{opacity:.6;transition:opacity .2s}.slideshare .inner,.speakerdeck .inner{position:relative;width:100%}.slideshare .inner iframe,.speakerdeck .inner iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%}.figma{display:table;position:relative;width:100%;padding-bottom:56.25%}.figma iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%;border:1px solid #eee}.MJX_Assistive_MathML{display:none}#MathJax_Message{z-index:1000!important}.ui-infobar{position:relative;z-index:2;max-width:760px;margin:25px auto -25px;color:#777}.toc .invisable-node{list-style-type:none}.ui-toc{position:fixed;bottom:20px;z-index:998}.ui-toc.both-mode{margin-left:8px}.ui-toc.both-mode .ui-toc-label{height:40px;padding:10px 4px;border-top-left-radius:0;border-bottom-left-radius:0}.ui-toc-label{background-color:#e6e6e6;border:none;color:#868686;transition:opacity .2s}.ui-toc .open .ui-toc-label{opacity:1;color:#fff;transition:opacity .2s}.ui-toc-label:focus{opacity:.3;background-color:#ccc;color:#000}.ui-toc-label:hover{opacity:1;background-color:#ccc;transition:opacity .2s}.ui-toc-dropdown{margin-top:20px;margin-bottom:20px;padding-left:10px;padding-right:10px;max-width:45vw;width:25vw;max-height:70vh;overflow:auto;text-align:inherit}.ui-toc-dropdown>.toc{max-height:calc(70vh - 100px);overflow:auto}.ui-toc-dropdown[dir=rtl] .nav{padding-right:0;letter-spacing:.0029em}.ui-toc-dropdown a{overflow:hidden;text-overflow:ellipsis;white-space:pre}.ui-toc-dropdown .nav>li>a{display:block;padding:4px 20px;font-size:13px;font-weight:500;color:#767676}.ui-toc-dropdown .nav>li:first-child:last-child>ul,.ui-toc-dropdown .toc.expand ul{display:block}.ui-toc-dropdown .nav>li>a:focus,.ui-toc-dropdown .nav>li>a:hover{padding-left:19px;color:#000;text-decoration:none;background-color:transparent;border-left:1px solid #000}.ui-toc-dropdown[dir=rtl] .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav>li>a:hover{padding-right:19px;border-left:none;border-right:1px solid #000}.ui-toc-dropdown .nav>.active:focus>a,.ui-toc-dropdown .nav>.active:hover>a,.ui-toc-dropdown .nav>.active>a{padding-left:18px;font-weight:700;color:#000;background-color:transparent;border-left:2px solid #000}.ui-toc-dropdown[dir=rtl] .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav>.active>a{padding-right:18px;border-left:none;border-right:2px solid #000}.ui-toc-dropdown .nav .nav{display:none;padding-bottom:10px}.ui-toc-dropdown .nav>.active>ul{display:block}.ui-toc-dropdown .nav .nav>li>a{padding-top:1px;padding-bottom:1px;padding-left:30px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a{padding-right:30px}.ui-toc-dropdown .nav .nav>li>ul>li>a{padding-top:1px;padding-bottom:1px;padding-left:40px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a{padding-right:40px}.ui-toc-dropdown .nav .nav>li>a:focus,.ui-toc-dropdown .nav .nav>li>a:hover{padding-left:29px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:hover{padding-right:29px}.ui-toc-dropdown .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown .nav .nav>li>ul>li>a:hover{padding-left:39px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:hover{padding-right:39px}.ui-toc-dropdown .nav .nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>a{padding-left:28px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>a{padding-right:28px}.ui-toc-dropdown .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active>a{padding-left:38px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active>a{padding-right:38px}.markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif}html[lang^=ja] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html .markdown-body[lang^=ja]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html .markdown-body[lang=zh-tw]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html .markdown-body[lang=zh-cn]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html[lang^=ja] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html[lang=zh-tw] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html[lang=zh-cn] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}html .ui-toc-dropdown[lang^=ja]{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html .ui-toc-dropdown[lang=zh-tw]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html .ui-toc-dropdown[lang=zh-cn]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}.ui-affix-toc{position:fixed;top:0;max-width:15vw;max-height:70vh;overflow:auto}.back-to-top,.expand-toggle,.go-to-bottom{display:block;padding:4px 10px;margin-top:10px;margin-left:10px;font-size:12px;font-weight:500;color:#999}.back-to-top:focus,.back-to-top:hover,.expand-toggle:focus,.expand-toggle:hover,.go-to-bottom:focus,.go-to-bottom:hover{color:#563d7c;text-decoration:none}.back-to-top,.go-to-bottom{margin-top:0}.ui-user-icon{width:20px;height:20px;display:block;border-radius:50%;margin-top:2px;margin-bottom:2px;margin-right:5px;background-position:50%;background-repeat:no-repeat;background-size:cover}.ui-user-icon.small{width:18px;height:18px;display:inline-block;vertical-align:middle;margin:0 0 .2em}.ui-infobar>small>span{line-height:22px}.ui-infobar>small .dropdown{display:inline-block}.ui-infobar>small .dropdown a:focus,.ui-infobar>small .dropdown a:hover{text-decoration:none}.ui-more-info{color:#888;cursor:pointer;vertical-align:middle}.ui-more-info .fa{font-size:16px}.ui-connectedGithub,.ui-published-note{color:#888}.ui-connectedGithub{line-height:23px;white-space:nowrap}.ui-connectedGithub a.file-path{color:#888;text-decoration:none;padding-left:22px}.ui-connectedGithub a.file-path:active,.ui-connectedGithub a.file-path:hover{color:#888;text-decoration:underline}.ui-connectedGithub .fa{font-size:20px}.ui-published-note .fa{font-size:20px;vertical-align:top}.unselectable{-webkit-user-select:none;-o-user-select:none;user-select:none}.selectable{-webkit-user-select:text;-o-user-select:text;user-select:text}@media print{blockquote,div,img,pre,table{page-break-inside:avoid!important}a[href]:after{font-size:12px!important}}.markdown-body.slides{position:relative;z-index:1;color:#222}.markdown-body.slides:before{content:"";display:block;position:absolute;top:0;left:0;right:0;bottom:0;z-index:-1;background-color:currentColor;box-shadow:0 0 0 50vw}.markdown-body.slides section[data-markdown]{position:relative;margin-bottom:1.5em;background-color:#fff;text-align:center}.markdown-body.slides section[data-markdown] code{text-align:left}.markdown-body.slides section[data-markdown]:before{content:"";display:block;padding-bottom:56.23%}.markdown-body.slides section[data-markdown]>div:first-child{position:absolute;top:50%;left:1em;right:1em;transform:translateY(-50%);max-height:100%;overflow:hidden}.markdown-body.slides section[data-markdown]>ul{display:inline-block}.markdown-body.slides>section>section+section:after{content:"";position:absolute;top:-1.5em;right:1em;height:1.5em;border:3px solid #777}.site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}body{font-smoothing:subpixel-antialiased!important;-webkit-font-smoothing:subpixel-antialiased!important;-moz-osx-font-smoothing:auto!important;text-shadow:0 0 1em transparent,1px 1px 1.2px rgba(0,0,0,.004);-webkit-overflow-scrolling:touch;letter-spacing:.025em;font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] body{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}abbr[data-original-title],abbr[title]{cursor:help}body.modal-open{overflow-y:auto;padding-right:0!important}
    </style>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js" integrity="sha256-g6iAfvZp+nDQ2TdTR/VVKJf3bGro4ub5fvWSWVRi2NE=" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js" integrity="sha256-8E4Is26QH0bD52WoQpcB+R/tcWQtpzlCojrybUd7Mxo=" crossorigin="anonymous"></script>
    <![endif]-->
</head>

<body>
    <div id="doc" class="markdown-body container-fluid comment-enabled" data-hard-breaks="true"><h1 id="DIP-2021-spring-Final-Project-—-Object-Detection" data-id="DIP-2021-spring-Final-Project-—-Object-Detection"><a class="anchor hidden-xs" href="#DIP-2021-spring-Final-Project-—-Object-Detection" title="DIP-2021-spring-Final-Project-—-Object-Detection"><span class="octicon octicon-link"></span></a><span>DIP 2021 spring Final Project — Object Detection</span></h1><blockquote>
<p><small><i class="fa fa-user"></i> 0712238 Yan-Tong Lin</small></p>
</blockquote><h2 id="Links-of-Codes-and-Results" data-id="Links-of-Codes-and-Results"><a class="anchor hidden-xs" href="#Links-of-Codes-and-Results" title="Links-of-Codes-and-Results"><span class="octicon octicon-link"></span></a><span>Links of Codes and Results</span></h2><ul>
<li><a href="https://hackmd.io/@ytlin/DIP-final" target="_blank" rel="noopener"><span>the online version of this report</span></a></li>
<li><a href="https://github.com/EazyReal/DIP2021spring/tree/main/final" target="_blank" rel="noopener"><span>GitHub repo link</span></a></li>
<li><a href="https://drive.google.com/file/d/1eaSDmpRpWj3Wge4Ri5KWOuKXXICnAKjW/view?usp=sharing" target="_blank" rel="noopener"><span>video link (Google drive)</span></a></li>
<li><a href="https://youtu.be/MpvFo-i52r4" target="_blank" rel="noopener"><span>video link (Youtube)</span></a></li>
</ul><h2 id="Method" data-id="Method"><a class="anchor hidden-xs" href="#Method" title="Method"><span class="octicon octicon-link"></span></a><span>Method</span></h2><p><span>I adopt </span><code>yolov5</code><span>, a deep learning model, for this project. Though being not an official new version of YOLO and controversial, it is quite efficient and accurate (yolov5x </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-1-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 113%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>A</mi><msub><mi>P</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>50.4</mn></math>" role="presentation"><span id="MJXc-Node-1" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-2" class="mjx-mrow"><span id="MJXc-Node-3" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.501em; padding-bottom: 0.279em;">A</span></span><span id="MJXc-Node-4" class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.109em;"><span id="MJXc-Node-5" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.445em; padding-bottom: 0.279em; padding-right: 0.109em;">P</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-6" class="mjx-texatom" style=""><span id="MJXc-Node-7" class="mjx-mrow"><span id="MJXc-Node-8" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.39em; padding-bottom: 0.279em;">t</span></span><span id="MJXc-Node-9" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.224em; padding-bottom: 0.279em;">e</span></span><span id="MJXc-Node-10" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.224em; padding-bottom: 0.279em;">s</span></span><span id="MJXc-Node-11" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.39em; padding-bottom: 0.279em;">t</span></span></span></span></span></span><span id="MJXc-Node-12" class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.058em; padding-bottom: 0.335em;">=</span></span><span id="MJXc-Node-13" class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.39em; padding-bottom: 0.39em;">50.4</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi><msub><mi>P</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>50.4</mn></math></span></span><script type="math/tex" id="MathJax-Element-1">AP_{test} = 50.4</script></span><span>) for the task of multiscaled object detection. (The SOTA of multiscaled objective detection is swin transformer with </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-2-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" style="font-size: 113%; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>A</mi><msub><mi>P</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>58.7</mn></math>" role="presentation"><span id="MJXc-Node-14" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-15" class="mjx-mrow"><span id="MJXc-Node-16" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.501em; padding-bottom: 0.279em;">A</span></span><span id="MJXc-Node-17" class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.109em;"><span id="MJXc-Node-18" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.445em; padding-bottom: 0.279em; padding-right: 0.109em;">P</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-19" class="mjx-texatom" style=""><span id="MJXc-Node-20" class="mjx-mrow"><span id="MJXc-Node-21" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.39em; padding-bottom: 0.279em;">t</span></span><span id="MJXc-Node-22" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.224em; padding-bottom: 0.279em;">e</span></span><span id="MJXc-Node-23" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.224em; padding-bottom: 0.279em;">s</span></span><span id="MJXc-Node-24" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.39em; padding-bottom: 0.279em;">t</span></span></span></span></span></span><span id="MJXc-Node-25" class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.058em; padding-bottom: 0.335em;">=</span></span><span id="MJXc-Node-26" class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.39em; padding-bottom: 0.39em;">58.7</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi><msub><mi>P</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>58.7</mn></math></span></span><script type="math/tex" id="MathJax-Element-2">AP_{test}=	58.7</script></span><span> based on </span><a href="https://paperswithcode.com/sota/object-detection-on-coco" target="_blank" rel="noopener"><span>paperswithcode</span></a><span>) A brief introduction to YOLOv5 is given.</span></p><h3 id="YOLO-v5" data-id="YOLO-v5"><a class="anchor hidden-xs" href="#YOLO-v5" title="YOLO-v5"><span class="octicon octicon-link"></span></a><span>YOLO v5</span></h3><p><img src="https://i.imgur.com/PMYoiHH.png" alt="" loading="lazy"></p><blockquote>
<p><span>from </span><a href="https://zhuanlan.zhihu.com/p/172121380" target="_blank" rel="noopener"><span>https://zhuanlan.zhihu.com/p/172121380</span></a></p>
</blockquote><p><span>YOLOs is a series of models designed manually to specialize in real time multi-scaled object detection.</span><br>
<span>The architecture of YOLO v5, similar to its v3, v4 counterparts, can be decomposed to 4 parts — Input, Backbone, Neck, and Head.</span><br>
<span>A variety of strategies and improvements is applied throughout the 4 building blocks of the model.</span></p><ul>
<li><span>Input (data enhancement)</span>
<ul>
<li><span>Mosaic data enhancement</span></li>
<li><span>adaptive anchoring</span></li>
<li><span>etc.</span></li>
</ul>
</li>
<li><span>Backbone (feature extraction)</span>
<ul>
<li><span>Focus</span></li>
<li><span>CSPDarknet</span>
<ul>
<li><span>solves the problems of repeated gradient information in large-scale backbones and integrates the gradient changes into the feature map.</span></li>
</ul>
</li>
</ul>
</li>
<li><span>Neck (feature fusion)</span>
<ul>
<li><span>PAN+FPN</span>
<ul>
<li><span>enhanced bottom-up path, which improves the propagation of low-level features.</span></li>
</ul>
</li>
</ul>
</li>
<li><span>Head (prediction)</span>
<ul>
<li><span>Yolo Layer</span>
<ul>
<li><span>different sizes of feature maps to achieve multi-scale prediction.</span></li>
</ul>
</li>
<li><span>GIOU_Loss</span></li>
</ul>
</li>
</ul><h3 id="Source-Code-—-my_detectpy" data-id="Source-Code-—-my_detectpy"><a class="anchor hidden-xs" href="#Source-Code-—-my_detectpy" title="Source-Code-—-my_detectpy"><span class="octicon octicon-link"></span></a><span>Source Code — </span><code>my_detect.py</code></h3><p><span>To meet the requirements (display my student id and the object counts), I modify </span><code>detect.py</code><span> of </span><code>yolov5</code><span> project to </span><code>my_detect.py</code><span>. The source code of </span><code>my_detect.py</code><span> is attached below.</span><br>
<span>If the source code is cut due to the limitation of page width, please visit </span><a href="https://hackmd.io/@ytlin/DIP-final" target="_blank" rel="noopener"><span>the online version of this report</span></a><span> or </span><a href="https://github.com/EazyReal/DIP2021spring/tree/main/final" target="_blank" rel="noopener"><span>the GitHub repo</span></a><span>.</span></p><pre><code class="=python hljs"><span class="hljs-keyword">import</span> argparse
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path

<span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.backends.cudnn <span class="hljs-keyword">as</span> cudnn

<span class="hljs-keyword">from</span> models.experimental <span class="hljs-keyword">import</span> attempt_load
<span class="hljs-keyword">from</span> utils.datasets <span class="hljs-keyword">import</span> LoadStreams, LoadImages
<span class="hljs-keyword">from</span> utils.general <span class="hljs-keyword">import</span> check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \
    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path, save_one_box
<span class="hljs-keyword">from</span> utils.plots <span class="hljs-keyword">import</span> colors, plot_one_box
<span class="hljs-keyword">from</span> utils.torch_utils <span class="hljs-keyword">import</span> select_device, load_classifier, time_synchronized


<span class="hljs-comment"># 0712238, for counting with defaultdict(int)</span>
<span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict


<span class="hljs-meta">@torch.no_grad()</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">detect</span>(<span class="hljs-params">opt</span>):</span>
    source, weights, view_img, save_txt, imgsz = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size
    save_img = <span class="hljs-keyword">not</span> opt.nosave <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> source.endswith(<span class="hljs-string">'.txt'</span>)  <span class="hljs-comment"># save inference images</span>
    webcam = source.isnumeric() <span class="hljs-keyword">or</span> source.endswith(<span class="hljs-string">'.txt'</span>) <span class="hljs-keyword">or</span> source.lower().startswith(
        (<span class="hljs-string">'rtsp://'</span>, <span class="hljs-string">'rtmp://'</span>, <span class="hljs-string">'http://'</span>, <span class="hljs-string">'https://'</span>))

    <span class="hljs-comment"># Directories</span>
    save_dir = increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok)  <span class="hljs-comment"># increment run</span>
    (save_dir / <span class="hljs-string">'labels'</span> <span class="hljs-keyword">if</span> save_txt <span class="hljs-keyword">else</span> save_dir).mkdir(parents=<span class="hljs-literal">True</span>, exist_ok=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># make dir</span>

    <span class="hljs-comment"># Initialize</span>
    set_logging()
    device = select_device(opt.device)
    half = opt.half <span class="hljs-keyword">and</span> device.<span class="hljs-built_in">type</span> != <span class="hljs-string">'cpu'</span>  <span class="hljs-comment"># half precision only supported on CUDA</span>

    <span class="hljs-comment"># Load model</span>
    model = attempt_load(weights, map_location=device)  <span class="hljs-comment"># load FP32 model</span>
    stride = <span class="hljs-built_in">int</span>(model.stride.<span class="hljs-built_in">max</span>())  <span class="hljs-comment"># model stride</span>
    imgsz = check_img_size(imgsz, s=stride)  <span class="hljs-comment"># check img_size</span>
    names = model.module.names <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(model, <span class="hljs-string">'module'</span>) <span class="hljs-keyword">else</span> model.names  <span class="hljs-comment"># get class names</span>
    <span class="hljs-keyword">if</span> half:
        model.half()  <span class="hljs-comment"># to FP16</span>

    <span class="hljs-comment"># Second-stage classifier</span>
    classify = <span class="hljs-literal">False</span>
    <span class="hljs-keyword">if</span> classify:
        modelc = load_classifier(name=<span class="hljs-string">'resnet101'</span>, n=<span class="hljs-number">2</span>)  <span class="hljs-comment"># initialize</span>
        modelc.load_state_dict(torch.load(<span class="hljs-string">'weights/resnet101.pt'</span>, map_location=device)[<span class="hljs-string">'model'</span>]).to(device).<span class="hljs-built_in">eval</span>()

    <span class="hljs-comment"># Set Dataloader</span>
    vid_path, vid_writer = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>
    <span class="hljs-keyword">if</span> webcam:
        view_img = check_imshow()
        cudnn.benchmark = <span class="hljs-literal">True</span>  <span class="hljs-comment"># set True to speed up constant image size inference</span>
        dataset = LoadStreams(source, img_size=imgsz, stride=stride)
    <span class="hljs-keyword">else</span>:
        dataset = LoadImages(source, img_size=imgsz, stride=stride)

    <span class="hljs-comment"># Run inference</span>
    <span class="hljs-keyword">if</span> device.<span class="hljs-built_in">type</span> != <span class="hljs-string">'cpu'</span>:
        model(torch.zeros(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, imgsz, imgsz).to(device).type_as(<span class="hljs-built_in">next</span>(model.parameters())))  <span class="hljs-comment"># run once</span>
    t0 = time.time()
    <span class="hljs-keyword">for</span> path, img, im0s, vid_cap <span class="hljs-keyword">in</span> dataset:
        img = torch.from_numpy(img).to(device)
        img = img.half() <span class="hljs-keyword">if</span> half <span class="hljs-keyword">else</span> img.<span class="hljs-built_in">float</span>()  <span class="hljs-comment"># uint8 to fp16/32</span>
        img /= <span class="hljs-number">255.0</span>  <span class="hljs-comment"># 0 - 255 to 0.0 - 1.0</span>
        <span class="hljs-keyword">if</span> img.ndimension() == <span class="hljs-number">3</span>:
            img = img.unsqueeze(<span class="hljs-number">0</span>)

        <span class="hljs-comment"># Inference</span>
        t1 = time_synchronized()
        pred = model(img, augment=opt.augment)[<span class="hljs-number">0</span>]

        <span class="hljs-comment"># Apply NMS</span>
        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, opt.classes, opt.agnostic_nms,
                                   max_det=opt.max_det)
        t2 = time_synchronized()

        <span class="hljs-comment"># Apply Classifier</span>
        <span class="hljs-keyword">if</span> classify:
            pred = apply_classifier(pred, modelc, img, im0s)

        <span class="hljs-comment"># Process detections</span>
        <span class="hljs-keyword">for</span> i, det <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(pred):  <span class="hljs-comment"># detections per image</span>
            <span class="hljs-keyword">if</span> webcam:  <span class="hljs-comment"># batch_size &gt;= 1</span>
                p, s, im0, frame = path[i], <span class="hljs-string">f'<span class="hljs-subst">{i}</span>: '</span>, im0s[i].copy(), dataset.count
            <span class="hljs-keyword">else</span>:
                p, s, im0, frame = path, <span class="hljs-string">''</span>, im0s.copy(), <span class="hljs-built_in">getattr</span>(dataset, <span class="hljs-string">'frame'</span>, <span class="hljs-number">0</span>)

            p = Path(p)  <span class="hljs-comment"># to Path</span>
            save_path = <span class="hljs-built_in">str</span>(save_dir / p.name)  <span class="hljs-comment"># img.jpg</span>
            txt_path = <span class="hljs-built_in">str</span>(save_dir / <span class="hljs-string">'labels'</span> / p.stem) + (<span class="hljs-string">''</span> <span class="hljs-keyword">if</span> dataset.mode == <span class="hljs-string">'image'</span> <span class="hljs-keyword">else</span> <span class="hljs-string">f'_<span class="hljs-subst">{frame}</span>'</span>)  <span class="hljs-comment"># img.txt</span>
            s += <span class="hljs-string">'%gx%g '</span> % img.shape[<span class="hljs-number">2</span>:]  <span class="hljs-comment"># print string</span>
            gn = torch.tensor(im0.shape)[[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]]  <span class="hljs-comment"># normalization gain whwh</span>
            imc = im0.copy() <span class="hljs-keyword">if</span> opt.save_crop <span class="hljs-keyword">else</span> im0  <span class="hljs-comment"># for opt.save_crop</span>
            <span class="hljs-comment"># 0712238</span>
            cnt = defaultdict(<span class="hljs-built_in">int</span>)
            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(det):
                <span class="hljs-comment"># Rescale boxes from img_size to im0 size</span>
                det[:, :<span class="hljs-number">4</span>] = scale_coords(img.shape[<span class="hljs-number">2</span>:], det[:, :<span class="hljs-number">4</span>], im0.shape).<span class="hljs-built_in">round</span>()

                <span class="hljs-comment"># Print results</span>
                <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> det[:, -<span class="hljs-number">1</span>].unique():
                    n = (det[:, -<span class="hljs-number">1</span>] == c).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment"># detections per class</span>
                    s += <span class="hljs-string">f"<span class="hljs-subst">{n}</span> <span class="hljs-subst">{names[<span class="hljs-built_in">int</span>(c)]}</span><span class="hljs-subst">{<span class="hljs-string">'s'</span> * (n &gt; <span class="hljs-number">1</span>)}</span>, "</span>  <span class="hljs-comment"># add to string</span>

                <span class="hljs-comment"># Write results</span>
                <span class="hljs-keyword">for</span> *xyxy, conf, cls <span class="hljs-keyword">in</span> <span class="hljs-built_in">reversed</span>(det):
                    <span class="hljs-keyword">if</span> save_txt:  <span class="hljs-comment"># Write to file</span>
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>)) / gn).view(-<span class="hljs-number">1</span>).tolist()  <span class="hljs-comment"># normalized xywh</span>
                        line = (cls, *xywh, conf) <span class="hljs-keyword">if</span> opt.save_conf <span class="hljs-keyword">else</span> (cls, *xywh)  <span class="hljs-comment"># label format</span>
                        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(txt_path + <span class="hljs-string">'.txt'</span>, <span class="hljs-string">'a'</span>) <span class="hljs-keyword">as</span> f:
                            f.write((<span class="hljs-string">'%g '</span> * <span class="hljs-built_in">len</span>(line)).rstrip() % line + <span class="hljs-string">'\n'</span>)

                    <span class="hljs-keyword">if</span> save_img <span class="hljs-keyword">or</span> opt.save_crop <span class="hljs-keyword">or</span> view_img:  <span class="hljs-comment"># Add bbox to image</span>
                        c = <span class="hljs-built_in">int</span>(cls)  <span class="hljs-comment"># integer class</span>
                        <span class="hljs-comment">## 0712238, filter out irrelevant results</span>
                        <span class="hljs-keyword">if</span> names[c] <span class="hljs-keyword">in</span> opt.cls:
                            cnt[names[c]] += <span class="hljs-number">1</span>
                            label = <span class="hljs-literal">None</span> <span class="hljs-keyword">if</span> opt.hide_labels <span class="hljs-keyword">else</span> (names[c] <span class="hljs-keyword">if</span> opt.hide_conf <span class="hljs-keyword">else</span> <span class="hljs-string">f'<span class="hljs-subst">{names[c]}</span> <span class="hljs-subst">{conf:<span class="hljs-number">.2</span>f}</span>'</span>)
                            plot_one_box(xyxy, im0, label=label, color=colors(c, <span class="hljs-literal">True</span>), line_thickness=opt.line_thickness)
                            <span class="hljs-keyword">if</span> opt.save_crop:
                                save_one_box(xyxy, imc, file=save_dir / <span class="hljs-string">'crops'</span> / names[c] / <span class="hljs-string">f'<span class="hljs-subst">{p.stem}</span>.jpg'</span>, BGR=<span class="hljs-literal">True</span>)

            <span class="hljs-comment"># 0712238, print counts</span>
            text = <span class="hljs-string">'0712238\n'</span>
            <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> opt.cls:
                <span class="hljs-keyword">if</span> c == <span class="hljs-string">'person'</span>:
                    text += <span class="hljs-string">f'the number of people detected: <span class="hljs-subst">{cnt[c]}</span>\n'</span>
                <span class="hljs-keyword">else</span>:
                    text += <span class="hljs-string">f'the number of <span class="hljs-subst">{c}</span>s detected: <span class="hljs-subst">{cnt[c]}</span>\n'</span>
            y0, dy = <span class="hljs-number">100</span>, <span class="hljs-number">50</span>
            <span class="hljs-keyword">for</span> i, txt <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(text.split(<span class="hljs-string">'\n'</span>)):
                y = y0+i*dy
                <span class="hljs-comment"># image, text, coord, font, size, color, thickness, anti-aliasing</span>
                cv2.putText(im0, txt, (<span class="hljs-number">100</span>, y), cv2.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">1.5</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">2</span>, cv2.LINE_AA)
            
            <span class="hljs-comment"># Print time (inference + NMS)</span>
            print(<span class="hljs-string">f'<span class="hljs-subst">{s}</span>Done. (<span class="hljs-subst">{t2 - t1:<span class="hljs-number">.3</span>f}</span>s)'</span>)

            <span class="hljs-comment"># Stream results</span>
            <span class="hljs-keyword">if</span> view_img:
                cv2.imshow(<span class="hljs-built_in">str</span>(p), im0)
                cv2.waitKey(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 1 millisecond</span>

            <span class="hljs-comment"># Save results (image with detections)</span>
            <span class="hljs-keyword">if</span> save_img:
                <span class="hljs-keyword">if</span> dataset.mode == <span class="hljs-string">'image'</span>:
                    cv2.imwrite(save_path, im0)
                <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># 'video' or 'stream'</span>
                    <span class="hljs-keyword">if</span> vid_path != save_path:  <span class="hljs-comment"># new video</span>
                        vid_path = save_path
                        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(vid_writer, cv2.VideoWriter):
                            vid_writer.release()  <span class="hljs-comment"># release previous video writer</span>
                        <span class="hljs-keyword">if</span> vid_cap:  <span class="hljs-comment"># video</span>
                            fps = vid_cap.get(cv2.CAP_PROP_FPS)
                            w = <span class="hljs-built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                            h = <span class="hljs-built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># stream</span>
                            fps, w, h = <span class="hljs-number">30</span>, im0.shape[<span class="hljs-number">1</span>], im0.shape[<span class="hljs-number">0</span>]
                            save_path += <span class="hljs-string">'.mp4'</span>
                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*<span class="hljs-string">'mp4v'</span>), fps, (w, h))
                    vid_writer.write(im0)

    <span class="hljs-keyword">if</span> save_txt <span class="hljs-keyword">or</span> save_img:
        s = <span class="hljs-string">f"\n<span class="hljs-subst">{<span class="hljs-built_in">len</span>(<span class="hljs-built_in">list</span>(save_dir.glob(<span class="hljs-string">'labels/*.txt'</span>)))}</span> labels saved to <span class="hljs-subst">{save_dir / <span class="hljs-string">'labels'</span>}</span>"</span> <span class="hljs-keyword">if</span> save_txt <span class="hljs-keyword">else</span> <span class="hljs-string">''</span>
        print(<span class="hljs-string">f"Results saved to <span class="hljs-subst">{save_dir}</span><span class="hljs-subst">{s}</span>"</span>)

    print(<span class="hljs-string">f'Done. (<span class="hljs-subst">{time.time() - t0:<span class="hljs-number">.3</span>f}</span>s)'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    parser = argparse.ArgumentParser()
    parser.add_argument(<span class="hljs-string">'--weights'</span>, nargs=<span class="hljs-string">'+'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">'yolov5s.pt'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'model.pt path(s)'</span>)
    parser.add_argument(<span class="hljs-string">'--source'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">'data/images'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'source'</span>)  <span class="hljs-comment"># file/folder, 0 for webcam</span>
    parser.add_argument(<span class="hljs-string">'--img-size'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">640</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'inference size (pixels)'</span>)
    parser.add_argument(<span class="hljs-string">'--conf-thres'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.25</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'object confidence threshold'</span>)
    parser.add_argument(<span class="hljs-string">'--iou-thres'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.45</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'IOU threshold for NMS'</span>)
    parser.add_argument(<span class="hljs-string">'--max-det'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1000</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'maximum number of detections per image'</span>)
    parser.add_argument(<span class="hljs-string">'--device'</span>, default=<span class="hljs-string">''</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'cuda device, i.e. 0 or 0,1,2,3 or cpu'</span>)
    parser.add_argument(<span class="hljs-string">'--view-img'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'display results'</span>)
    parser.add_argument(<span class="hljs-string">'--save-txt'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'save results to *.txt'</span>)
    parser.add_argument(<span class="hljs-string">'--save-conf'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'save confidences in --save-txt labels'</span>)
    parser.add_argument(<span class="hljs-string">'--save-crop'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'save cropped prediction boxes'</span>)
    parser.add_argument(<span class="hljs-string">'--nosave'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'do not save images/videos'</span>)
    parser.add_argument(<span class="hljs-string">'--classes'</span>, nargs=<span class="hljs-string">'+'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'filter by class: --class 0, or --class 0 2 3'</span>)
    parser.add_argument(<span class="hljs-string">'--agnostic-nms'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'class-agnostic NMS'</span>)
    parser.add_argument(<span class="hljs-string">'--augment'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'augmented inference'</span>)
    parser.add_argument(<span class="hljs-string">'--update'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'update all models'</span>)
    parser.add_argument(<span class="hljs-string">'--project'</span>, default=<span class="hljs-string">'runs/detect'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'save results to project/name'</span>)
    parser.add_argument(<span class="hljs-string">'--name'</span>, default=<span class="hljs-string">'exp'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'save results to project/name'</span>)
    parser.add_argument(<span class="hljs-string">'--exist-ok'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'existing project/name ok, do not increment'</span>)
    parser.add_argument(<span class="hljs-string">'--line-thickness'</span>, default=<span class="hljs-number">3</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'bounding box thickness (pixels)'</span>)
    parser.add_argument(<span class="hljs-string">'--hide-labels'</span>, default=<span class="hljs-literal">False</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'hide labels'</span>)
    parser.add_argument(<span class="hljs-string">'--hide-conf'</span>, default=<span class="hljs-literal">False</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'hide confidences'</span>)
    parser.add_argument(<span class="hljs-string">'--half'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'use FP16 half-precision inference'</span>)
    <span class="hljs-comment">## 0712238, add option to filter out irrelevant classes and show only the desired clasees</span>
    parser.add_argument(<span class="hljs-string">'--cls'</span>, nargs=<span class="hljs-string">'+'</span>, default=[], <span class="hljs-built_in">help</span>=<span class="hljs-string">'filter by the names of desired classes: --cls bicycle person'</span>)
    opt = parser.parse_args()
    print(opt)
    check_requirements(exclude=(<span class="hljs-string">'tensorboard'</span>, <span class="hljs-string">'thop'</span>))

    <span class="hljs-keyword">if</span> opt.update:  <span class="hljs-comment"># update all models (to fix SourceChangeWarning)</span>
        <span class="hljs-keyword">for</span> opt.weights <span class="hljs-keyword">in</span> [<span class="hljs-string">'yolov5s.pt'</span>, <span class="hljs-string">'yolov5m.pt'</span>, <span class="hljs-string">'yolov5l.pt'</span>, <span class="hljs-string">'yolov5x.pt'</span>]:
            detect(opt=opt)
            strip_optimizer(opt.weights)
    <span class="hljs-keyword">else</span>:
        detect(opt=opt)
</code></pre><h3 id="A-Step-by-Step-Guide-to-Reproduce-the-Result" data-id="A-Step-by-Step-Guide-to-Reproduce-the-Result"><a class="anchor hidden-xs" href="#A-Step-by-Step-Guide-to-Reproduce-the-Result" title="A-Step-by-Step-Guide-to-Reproduce-the-Result"><span class="octicon octicon-link"></span></a><span>A Step by Step Guide to Reproduce the Result</span></h3><ul>
<li><span>prepare your video</span></li>
<li><span>clone the yolov5 project</span>
<ul>
<li><code>git clone https://github.com/ultralytics/yolov5.git</code></li>
</ul>
</li>
<li><span>use </span><code>my_detect.py</code><span> to get the result</span>
<ul>
<li><code>python my_detect.py --source {your video} --cls {desired classes} --weights {yolo weight}</code></li>
</ul>
</li>
<li><span>the project hierarchy</span></li>
</ul><pre><code>final/
    - yolov5/
        - my_detect.py
        - ...
    - sample_videos/
        - person_bicycle.mp4
        - ...
</code></pre><ul>
<li><span>the parameters for my result</span>
<ul>
<li><code>python my_detect.py --source ..\sample_videos\person_bicycle.mp4 --cls person bicycle --weights yolov5x.pt</code></li>
</ul>
</li>
</ul><h2 id="A-Better-Performance" data-id="A-Better-Performance"><a class="anchor hidden-xs" href="#A-Better-Performance" title="A-Better-Performance"><span class="octicon octicon-link"></span></a><span>A Better Performance</span></h2><p><span>A better performance is illustrated in the following screen shots.</span><br>
<span>The adopted model successfully detects the pair of person and bicyble in the back of another pair as well as avoids the misclassification in the middle of the picture.</span></p><ul>
<li><span>baseline (YOLOv3)</span><br>
<img src="https://i.imgur.com/j2fYSX3.jpg" alt="" loading="lazy"></li>
<li><span>this work (YOLOv5)</span><br>
<img src="https://i.imgur.com/O8GgrGE.jpg" alt="" loading="lazy"></li>
</ul><p><span>YOLOv5 is a relatively new model compared to the baseline (YOLOv3), so it is not surprising that it outperforms YOLOv3. Also, I adopt the </span><code>yolov5x</code><span> weight, which is the largest model available, to do the inference.</span></p><h2 id="Possibilities-for-Further-Improvement" data-id="Possibilities-for-Further-Improvement"><a class="anchor hidden-xs" href="#Possibilities-for-Further-Improvement" title="Possibilities-for-Further-Improvement"><span class="octicon octicon-link"></span></a><span>Possibilities for Further Improvement</span></h2><h3 id="Swin-Transformer" data-id="Swin-Transformer"><a class="anchor hidden-xs" href="#Swin-Transformer" title="Swin-Transformer"><span class="octicon octicon-link"></span></a><span>Swin Transformer</span></h3><p><img src="https://i.imgur.com/WXkveIE.png" alt="" loading="lazy"></p><blockquote>
<p><span>from </span><a href="https://arxiv.org/pdf/2103.14030.pdf" target="_blank" rel="noopener"><span>https://arxiv.org/pdf/2103.14030.pdf</span></a></p>
</blockquote><p><span>According to </span><a href="https://paperswithcode.com/sota/object-detection-on-coco" target="_blank" rel="noopener"><span>paperswithcode</span></a><span>, the SOTA of multiscaled objective detection is based on </span><a href="https://arxiv.org/pdf/2103.14030.pdf" target="_blank" rel="noopener"><span>swin transformer</span></a><span> with </span><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"></span><span id="MathJax-Element-3-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>A</mi><msub><mi>P</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>58.7</mn></math>" role="presentation" style="font-size: 113%; position: relative;"><span id="MJXc-Node-27" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-28" class="mjx-mrow"><span id="MJXc-Node-29" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.501em; padding-bottom: 0.279em;">A</span></span><span id="MJXc-Node-30" class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.109em;"><span id="MJXc-Node-31" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.445em; padding-bottom: 0.279em; padding-right: 0.109em;">P</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-32" class="mjx-texatom" style=""><span id="MJXc-Node-33" class="mjx-mrow"><span id="MJXc-Node-34" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.39em; padding-bottom: 0.279em;">t</span></span><span id="MJXc-Node-35" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.224em; padding-bottom: 0.279em;">e</span></span><span id="MJXc-Node-36" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.224em; padding-bottom: 0.279em;">s</span></span><span id="MJXc-Node-37" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.39em; padding-bottom: 0.279em;">t</span></span></span></span></span></span><span id="MJXc-Node-38" class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.058em; padding-bottom: 0.335em;">=</span></span><span id="MJXc-Node-39" class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.39em; padding-bottom: 0.39em;">58.7</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi><msub><mi>P</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>58.7</mn></math></span></span><script type="math/tex" id="MathJax-Element-3">AP_{test}=58.7</script></span><span>. Swin transformer is a successful attempt to apply transformers (which I am familiar with due to my experience during the summer internship at IIS NLU lab) to computer vision tasks. It utilizes “Shifted Window based Multihead Self Attention” and other features to preserve the advantages of CNNs (locality, translation invariance, hierarchical), incorporate the advantages of transformers (computational power), and remain efficient enough.</span></p><h3 id="Finetuning" data-id="Finetuning"><a class="anchor hidden-xs" href="#Finetuning" title="Finetuning"><span class="octicon octicon-link"></span></a><span>Finetuning</span></h3><p><span>Since the assignment requires only the detection of people and bicycles, if we finetune the model with a dataset of people and bicycles and a loss function that ignores other classes, we may get a better result. Unfortunately, I do not have easy access to powerful GPU to do finetuning now.</span></p><h2 id="Resources" data-id="Resources"><a class="anchor hidden-xs" href="#Resources" title="Resources"><span class="octicon octicon-link"></span></a><span>Resources</span></h2><ul>
<li><a href="https://github.com/ultralytics/yolov5" target="_blank" rel="noopener"><span>https://github.com/ultralytics/yolov5</span></a></li>
<li><a href="https://github.com/microsoft/Swin-Transformer" target="_blank" rel="noopener"><span>https://github.com/microsoft/Swin-Transformer</span></a></li>
<li><a href="https://arxiv.org/pdf/2103.14030.pdf" target="_blank" rel="noopener"><span>https://arxiv.org/pdf/2103.14030.pdf</span></a></li>
<li><span>technical details of yolov5 model</span>
<ul>
<li><a href="https://www.researchgate.net/publication/349299852_A_Forest_Fire_Detection_System_Based_on_Ensemble_Learning" target="_blank" rel="noopener"><span>https://www.researchgate.net/publication/349299852_A_Forest_Fire_Detection_System_Based_on_Ensemble_Learning</span></a></li>
<li><a href="https://zhuanlan.zhihu.com/p/172121380" target="_blank" rel="noopener"><span>https://zhuanlan.zhihu.com/p/172121380</span></a></li>
<li><a href="https://www.233tw.com/algorithm/28664" target="_blank" rel="noopener"><span>https://www.233tw.com/algorithm/28664</span></a></li>
</ul>
</li>
<li><span>YOLO 1-5</span>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/334961642" target="_blank" rel="noopener"><span>https://zhuanlan.zhihu.com/p/334961642</span></a></li>
</ul>
</li>
</ul></div>
    <div class="ui-toc dropup unselectable hidden-print" style="display:none;">
        <div class="pull-right dropdown">
            <a id="tocLabel" class="ui-toc-label btn btn-default" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false" title="Table of content">
                <i class="fa fa-bars"></i>
            </a>
            <ul id="ui-toc" class="ui-toc-dropdown dropdown-menu" aria-labelledby="tocLabel">
                <div class="toc"><ul class="nav">
<li class=""><a href="#DIP-2021-spring-Final-Project-—-Object-Detection" title="DIP 2021 spring Final Project — Object Detection">DIP 2021 spring Final Project — Object Detection</a><ul class="nav">
<li><a href="#Links-of-Codes-and-Results" title="Links of Codes and Results">Links of Codes and Results</a></li>
<li><a href="#Method" title="Method">Method</a><ul class="nav">
<li><a href="#YOLO-v5" title="YOLO v5">YOLO v5</a></li>
<li><a href="#Source-Code-—-my_detectpy" title="Source Code — my_detect.py">Source Code — my_detect.py</a></li>
<li><a href="#A-Step-by-Step-Guide-to-Reproduce-the-Result" title="A Step by Step Guide to Reproduce the Result">A Step by Step Guide to Reproduce the Result</a></li>
</ul>
</li>
<li><a href="#A-Better-Performance" title="A Better Performance">A Better Performance</a></li>
<li><a href="#Possibilities-for-Further-Improvement" title="Possibilities for Further Improvement">Possibilities for Further Improvement</a><ul class="nav">
<li><a href="#Swin-Transformer" title="Swin Transformer">Swin Transformer</a></li>
<li><a href="#Finetuning" title="Finetuning">Finetuning</a></li>
</ul>
</li>
<li><a href="#Resources" title="Resources">Resources</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">全部展開</a><a class="back-to-top" href="#">回到頂部</a><a class="go-to-bottom" href="#">移至底部</a></div>
            </ul>
        </div>
    </div>
    <div id="ui-toc-affix" class="ui-affix-toc ui-toc-dropdown unselectable hidden-print" data-spy="affix" style="top:17px;display:none;" null null>
        <div class="toc"><ul class="nav">
<li class=""><a href="#DIP-2021-spring-Final-Project-—-Object-Detection" title="DIP 2021 spring Final Project — Object Detection">DIP 2021 spring Final Project — Object Detection</a><ul class="nav">
<li><a href="#Links-of-Codes-and-Results" title="Links of Codes and Results">Links of Codes and Results</a></li>
<li><a href="#Method" title="Method">Method</a><ul class="nav">
<li><a href="#YOLO-v5" title="YOLO v5">YOLO v5</a></li>
<li><a href="#Source-Code-—-my_detectpy" title="Source Code — my_detect.py">Source Code — my_detect.py</a></li>
<li><a href="#A-Step-by-Step-Guide-to-Reproduce-the-Result" title="A Step by Step Guide to Reproduce the Result">A Step by Step Guide to Reproduce the Result</a></li>
</ul>
</li>
<li class=""><a href="#A-Better-Performance" title="A Better Performance">A Better Performance</a></li>
<li><a href="#Possibilities-for-Further-Improvement" title="Possibilities for Further Improvement">Possibilities for Further Improvement</a><ul class="nav">
<li><a href="#Swin-Transformer" title="Swin Transformer">Swin Transformer</a></li>
<li><a href="#Finetuning" title="Finetuning">Finetuning</a></li>
</ul>
</li>
<li><a href="#Resources" title="Resources">Resources</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">全部展開</a><a class="back-to-top" href="#">回到頂部</a><a class="go-to-bottom" href="#">移至底部</a></div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous" defer></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.6.0/gist-embed.min.js" integrity="sha256-KyF2D6xPIJUW5sUDSs93vWyZm+1RzIpKCexxElmxl8g=" crossorigin="anonymous" defer></script>
    <script>
        var markdown = $(".markdown-body");
        //smooth all hash trigger scrolling
        function smoothHashScroll() {
            var hashElements = $("a[href^='#']").toArray();
            for (var i = 0; i < hashElements.length; i++) {
                var element = hashElements[i];
                var $element = $(element);
                var hash = element.hash;
                if (hash) {
                    $element.on('click', function (e) {
                        // store hash
                        var hash = this.hash;
                        if ($(hash).length <= 0) return;
                        // prevent default anchor click behavior
                        e.preventDefault();
                        // animate
                        $('body, html').stop(true, true).animate({
                            scrollTop: $(hash).offset().top
                        }, 100, "linear", function () {
                            // when done, add hash to url
                            // (default click behaviour)
                            window.location.hash = hash;
                        });
                    });
                }
            }
        }

        smoothHashScroll();
        var toc = $('.ui-toc');
        var tocAffix = $('.ui-affix-toc');
        var tocDropdown = $('.ui-toc-dropdown');
        //toc
        tocDropdown.click(function (e) {
            e.stopPropagation();
        });

        var enoughForAffixToc = true;

        function generateScrollspy() {
            $(document.body).scrollspy({
                target: ''
            });
            $(document.body).scrollspy('refresh');
            if (enoughForAffixToc) {
                toc.hide();
                tocAffix.show();
            } else {
                tocAffix.hide();
                toc.show();
            }
            $(document.body).scroll();
        }

        function windowResize() {
            //toc right
            var paddingRight = parseFloat(markdown.css('padding-right'));
            var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight));
            toc.css('right', right + 'px');
            //affix toc left
            var newbool;
            var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2;
            //for ipad or wider device
            if (rightMargin >= 133) {
                newbool = true;
                var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2;
                var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin;
                tocAffix.css('left', left + 'px');
            } else {
                newbool = false;
            }
            if (newbool != enoughForAffixToc) {
                enoughForAffixToc = newbool;
                generateScrollspy();
            }
        }
        $(window).resize(function () {
            windowResize();
        });
        $(document).ready(function () {
            windowResize();
            generateScrollspy();
        });

        //remove hash
        function removeHash() {
            window.location.hash = '';
        }

        var backtotop = $('.back-to-top');
        var gotobottom = $('.go-to-bottom');

        backtotop.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToTop)
                scrollToTop();
            removeHash();
        });
        gotobottom.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToBottom)
                scrollToBottom();
            removeHash();
        });

        var toggle = $('.expand-toggle');
        var tocExpand = false;

        checkExpandToggle();
        toggle.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            tocExpand = !tocExpand;
            checkExpandToggle();
        })

        function checkExpandToggle () {
            var toc = $('.ui-toc-dropdown .toc');
            var toggle = $('.expand-toggle');
            if (!tocExpand) {
                toc.removeClass('expand');
                toggle.text('Expand all');
            } else {
                toc.addClass('expand');
                toggle.text('Collapse all');
            }
        }

        function scrollToTop() {
            $('body, html').stop(true, true).animate({
                scrollTop: 0
            }, 100, "linear");
        }

        function scrollToBottom() {
            $('body, html').stop(true, true).animate({
                scrollTop: $(document.body)[0].scrollHeight
            }, 100, "linear");
        }
    </script>
</body>

</html>
